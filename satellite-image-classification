{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2546969,"sourceType":"datasetVersion","datasetId":1544742}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms","metadata":{"execution":{"iopub.status.busy":"2024-08-06T14:18:27.706363Z","iopub.execute_input":"2024-08-06T14:18:27.707088Z","iopub.status.idle":"2024-08-06T14:18:29.283538Z","shell.execute_reply.started":"2024-08-06T14:18:27.707057Z","shell.execute_reply":"2024-08-06T14:18:29.282716Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n])\n\nbatch_size = 64\n\ndata_dir = '/kaggle/input/satellite-image-classification/data'\ndata = datasets.ImageFolder(data_dir,transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T14:18:30.278280Z","iopub.execute_input":"2024-08-06T14:18:30.279285Z","iopub.status.idle":"2024-08-06T14:18:31.047141Z","shell.execute_reply.started":"2024-08-06T14:18:30.279253Z","shell.execute_reply":"2024-08-06T14:18:31.046357Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"n = len(data)\ntrain_len = int(n*0.8)\ntest_len = int(n-train_len)\n\ndata_train, data_test = random_split(data,[train_len,test_len])","metadata":{"execution":{"iopub.status.busy":"2024-08-06T14:18:31.326059Z","iopub.execute_input":"2024-08-06T14:18:31.327011Z","iopub.status.idle":"2024-08-06T14:18:31.348073Z","shell.execute_reply.started":"2024-08-06T14:18:31.326977Z","shell.execute_reply":"2024-08-06T14:18:31.347303Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dataloader_train = DataLoader(data_train,batch_size=batch_size,shuffle=True)\ndataloader_test = DataLoader(data_test,batch_size=batch_size,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T14:18:33.660113Z","iopub.execute_input":"2024-08-06T14:18:33.660912Z","iopub.status.idle":"2024-08-06T14:18:33.665440Z","shell.execute_reply.started":"2024-08-06T14:18:33.660881Z","shell.execute_reply":"2024-08-06T14:18:33.664444Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-08-06T14:18:35.379659Z","iopub.execute_input":"2024-08-06T14:18:35.380446Z","iopub.status.idle":"2024-08-06T14:18:35.406087Z","shell.execute_reply.started":"2024-08-06T14:18:35.380414Z","shell.execute_reply":"2024-08-06T14:18:35.404970Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"num_classes = len(dataloader_train.dataset.dataset.classes)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T14:18:36.847240Z","iopub.execute_input":"2024-08-06T14:18:36.848037Z","iopub.status.idle":"2024-08-06T14:18:36.851971Z","shell.execute_reply.started":"2024-08-06T14:18:36.848004Z","shell.execute_reply":"2024-08-06T14:18:36.851075Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tuple(dataloader_train.dataset.dataset.classes)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T14:20:16.437426Z","iopub.execute_input":"2024-08-06T14:20:16.438122Z","iopub.status.idle":"2024-08-06T14:20:16.443819Z","shell.execute_reply.started":"2024-08-06T14:20:16.438092Z","shell.execute_reply":"2024-08-06T14:20:16.442939Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"('cloudy', 'desert', 'green_area', 'water')"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Vgg16(nn.Module):\n    def __init__(self,num_classes=4):\n        super(Vgg16,self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3,64,3,stride=1,padding=2),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.Conv2d(64,64,3,stride=1,padding=2),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2,stride=2)\n        )\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(64,128,3,stride=1,padding=2),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.Conv2d(128,128,3,stride=1,padding=2),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2,stride=2)\n        )\n        self.layer3 = nn.Sequential(\n            nn.Conv2d(128,256,3,stride=1,padding=2),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.Conv2d(256,256,3,stride=1,padding=2),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.Conv2d(256,256,3,stride=1,padding=2),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2,stride=2)\n        )\n        self.layer4 = nn.Sequential(\n            nn.Conv2d(256,512,3,stride=1,padding=2),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.Conv2d(512,512,3,stride=1,padding=2),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.Conv2d(512,512,3,stride=1,padding=2),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2,stride=2)\n        )\n        self.layer5 = nn.Sequential(\n            nn.Conv2d(512,512,3,stride=1,padding=2),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.Conv2d(512,512,3,stride=1,padding=2),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.Conv2d(512,512,3,stride=1,padding=2),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2,stride=2)\n        )\n        self.layer6 = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(12*12*512,4096),\n            nn.ReLU()\n        )\n        self.layer7 = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(4096,4096),\n            nn.ReLU()\n        )\n        self.layer8 = nn.Sequential(\n            nn.Linear(4096,num_classes)\n        )\n\n    def forward(self,x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer5(x)\n#         print(x.shape)\n        x = torch.flatten(x,1)\n        x = self.layer6(x)\n        x = self.layer7(x)\n        x = self.layer8(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-08-06T14:20:22.642718Z","iopub.execute_input":"2024-08-06T14:20:22.643069Z","iopub.status.idle":"2024-08-06T14:20:22.662964Z","shell.execute_reply.started":"2024-08-06T14:20:22.643041Z","shell.execute_reply":"2024-08-06T14:20:22.662177Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model = Vgg16(num_classes).to(device)\nepochs=20\nlearning_rate = 1e-5\n\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n\n\nfor epoch in range(epochs):\n    for idx,(image,target) in enumerate(dataloader_train):\n        images = image.to(device)\n        target = target.to(device)\n\n        # forward pass\n        y_pred = model(images)\n        loss = criterion(y_pred,target)\n\n        # backward pass\n        loss.backward()\n\n        # weight pass\n        optimizer.step()\n\n        # reset the gradient\n        optimizer.zero_grad()\n    print(f'epoch number = {epoch}')","metadata":{"execution":{"iopub.status.busy":"2024-08-06T14:20:24.214032Z","iopub.execute_input":"2024-08-06T14:20:24.214566Z","iopub.status.idle":"2024-08-06T14:43:09.331772Z","shell.execute_reply.started":"2024-08-06T14:20:24.214530Z","shell.execute_reply":"2024-08-06T14:43:09.330751Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"epoch number = 0\nepoch number = 1\nepoch number = 2\nepoch number = 3\nepoch number = 4\nepoch number = 5\nepoch number = 6\nepoch number = 7\nepoch number = 8\nepoch number = 9\nepoch number = 10\nepoch number = 11\nepoch number = 12\nepoch number = 13\nepoch number = 14\nepoch number = 15\nepoch number = 16\nepoch number = 17\nepoch number = 18\nepoch number = 19\n","output_type":"stream"}]},{"cell_type":"code","source":"PATH = '/kaggle/working/vgg16C'\ntorch.save(model.state_dict(), PATH)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T14:43:09.333521Z","iopub.execute_input":"2024-08-06T14:43:09.333819Z","iopub.status.idle":"2024-08-06T14:43:12.226851Z","shell.execute_reply.started":"2024-08-06T14:43:09.333794Z","shell.execute_reply":"2024-08-06T14:43:12.225853Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model = Vgg16().to(device=device)\nmodel.load_state_dict(torch.load(PATH))","metadata":{"execution":{"iopub.status.busy":"2024-08-06T14:43:12.228193Z","iopub.execute_input":"2024-08-06T14:43:12.228482Z","iopub.status.idle":"2024-08-06T14:43:16.786849Z","shell.execute_reply.started":"2024-08-06T14:43:12.228458Z","shell.execute_reply":"2024-08-06T14:43:16.785929Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"correct = 0\ntotal = 0\ni=0\nwith torch.no_grad():\n    for data in dataloader_test:\n        image, label = data\n        image = image.to(device)\n        label = label.to(device)\n\n        output = model(image)\n\n        _,prediction = torch.max(output.data,1)\n\n        total += label.size(0)\n        correct += (prediction==label).sum().item()\n        print(i)\n        i+=1\n\nprint(f'The Accuracy of model is {100*(correct/total)} %')","metadata":{"execution":{"iopub.status.busy":"2024-08-06T14:43:16.788964Z","iopub.execute_input":"2024-08-06T14:43:16.789284Z","iopub.status.idle":"2024-08-06T14:43:28.180500Z","shell.execute_reply.started":"2024-08-06T14:43:16.789257Z","shell.execute_reply":"2024-08-06T14:43:28.179517Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\nThe Accuracy of model is 97.95918367346938 %\n","output_type":"stream"}]},{"cell_type":"code","source":"# prepare to count predictions for each class\nclasses = tuple(dataloader_train.dataset.dataset.classes)\ncorrect_pred = {classname: 0 for classname in classes}\ntotal_pred = {classname: 0 for classname in classes}\ni=0\n# again no gradients needed\nwith torch.no_grad():\n    for data in dataloader_test:\n        images, labels = data\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        _, predictions = torch.max(outputs, 1)\n        # collect the correct predictions for each class\n        for label, prediction in zip(labels, predictions):\n            if label == prediction:\n                correct_pred[classes[label]] += 1\n            total_pred[classes[label]] += 1\n        \n        print(i)\n        i+=1\n\n\n# print accuracy for each class\nfor classname, correct_count in correct_pred.items():\n    accuracy = 100 * float(correct_count) / total_pred[classname]\n    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')","metadata":{"execution":{"iopub.status.busy":"2024-08-06T14:43:28.181637Z","iopub.execute_input":"2024-08-06T14:43:28.181927Z","iopub.status.idle":"2024-08-06T14:43:35.690495Z","shell.execute_reply.started":"2024-08-06T14:43:28.181903Z","shell.execute_reply":"2024-08-06T14:43:35.689623Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\nAccuracy for class: cloudy is 96.9 %\nAccuracy for class: desert is 100.0 %\nAccuracy for class: green_area is 96.2 %\nAccuracy for class: water is 99.7 %\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}