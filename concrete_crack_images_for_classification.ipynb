{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3543368,"sourceType":"datasetVersion","datasetId":2130851}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch \nfrom torch import nn\nfrom torch.utils.data import DataLoader, random_split\nimport torchvision\nimport matplotlib.pyplot as plt\nfrom torchvision import datasets, transforms\nimport torch.nn.functional as F\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-08-05T17:39:50.483482Z","iopub.execute_input":"2024-08-05T17:39:50.484097Z","iopub.status.idle":"2024-08-05T17:39:50.489129Z","shell.execute_reply.started":"2024-08-05T17:39:50.484067Z","shell.execute_reply":"2024-08-05T17:39:50.488067Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((227,227)),\n    transforms.ToTensor(),\n#     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n#     transforms.functional.rgb_to_grayscale()\n])\n\nbatch_size = 128\n\ndata_dir = '/kaggle/input/concrete-crack-images-for-classification'\n\ndata = datasets.ImageFolder(data_dir, transform=transform)\n\n# dataloader = DataLoader(data,batch_size=batch_size,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T17:39:52.411490Z","iopub.execute_input":"2024-08-05T17:39:52.412216Z","iopub.status.idle":"2024-08-05T17:40:00.934683Z","shell.execute_reply.started":"2024-08-05T17:39:52.412186Z","shell.execute_reply":"2024-08-05T17:40:00.933770Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"n=len(data)\ntrain_size = int(n*0.8)\ntest_size= int(n*0.2)\ndata_train, data_test = random_split(data,[train_size,test_size])","metadata":{"execution":{"iopub.status.busy":"2024-08-05T17:40:00.936652Z","iopub.execute_input":"2024-08-05T17:40:00.936946Z","iopub.status.idle":"2024-08-05T17:40:00.944538Z","shell.execute_reply.started":"2024-08-05T17:40:00.936919Z","shell.execute_reply":"2024-08-05T17:40:00.943574Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"dataloader_train = DataLoader(data_train,batch_size=batch_size,shuffle=True)\ndataloader_test = DataLoader(data_test,batch_size=batch_size,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T17:40:02.565076Z","iopub.execute_input":"2024-08-05T17:40:02.565441Z","iopub.status.idle":"2024-08-05T17:40:02.572916Z","shell.execute_reply.started":"2024-08-05T17:40:02.565412Z","shell.execute_reply":"2024-08-05T17:40:02.571919Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T17:40:03.294274Z","iopub.execute_input":"2024-08-05T17:40:03.294633Z","iopub.status.idle":"2024-08-05T17:40:03.300763Z","shell.execute_reply.started":"2024-08-05T17:40:03.294604Z","shell.execute_reply":"2024-08-05T17:40:03.299838Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-08-05T17:40:04.357703Z","iopub.execute_input":"2024-08-05T17:40:04.358369Z","iopub.status.idle":"2024-08-05T17:40:04.362851Z","shell.execute_reply.started":"2024-08-05T17:40:04.358336Z","shell.execute_reply":"2024-08-05T17:40:04.361804Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn \nimport torch.nn.functional as F\n\nclass AlexNet(nn.Module):\n    def __init__(self,num_classes):\n        super(AlexNet,self).__init__()\n        self.conv1 = nn.Conv2d(3,96,11,stride=4,padding=0)\n        self.maxPool = nn.MaxPool2d(kernel_size=3,stride=2)\n        self.conv2 = nn.Conv2d(96,256,5,stride=1,padding=2)\n        self.conv3 = nn.Conv2d(256,384,3,stride=1,padding=1)\n        self.conv4 = nn.Conv2d(384,384,3,stride=1,padding=1)\n        self.conv5 = nn.Conv2d(384,256,3,stride=1,padding=1)\n        self.fc1 = nn.Linear(256*6*6,4096)\n        self.fc2 = nn.Linear(4096,4096)\n        self.fc3 = nn.Linear(4096,num_classes)\n        self.b1 = nn.BatchNorm2d(96)\n        self.b2 = nn.BatchNorm2d(256)\n        self.b3 = nn.BatchNorm2d(384)\n        self.d = nn.Dropout1d(0.5)\n\n    def forward(self,x):\n        x = self.maxPool(F.relu(self.b1(self.conv1(x))))\n        x = self.maxPool(F.relu(self.b2(self.conv2(x))))\n        x = F.relu(self.b3(self.conv3(x)))\n        x = F.relu(self.b3(self.conv4(x)))\n        x = self.maxPool(F.relu(self.b2(self.conv5(x))))\n        # x = torch.flatten(x,1)\n        x = x.reshape(x.size(0),-1)\n        x = F.relu(self.fc1(self.d(x)))\n        x = F.relu(self.fc2(self.d(x)))\n        x = F.relu(self.fc3(x))\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T17:40:07.679395Z","iopub.execute_input":"2024-08-05T17:40:07.679775Z","iopub.status.idle":"2024-08-05T17:40:07.692060Z","shell.execute_reply.started":"2024-08-05T17:40:07.679747Z","shell.execute_reply":"2024-08-05T17:40:07.691063Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class AlexNetB(nn.Module):\n    def __init__(self, num_classes=2):\n        super(AlexNetB, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n            nn.BatchNorm2d(96),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 3, stride = 2))\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 3, stride = 2))\n        self.layer3 = nn.Sequential(\n            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(384),\n            nn.ReLU())\n        self.layer4 = nn.Sequential(\n            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(384),\n            nn.ReLU())\n        self.layer5 = nn.Sequential(\n            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 3, stride = 2))\n        self.fc = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(9216, 4096),\n            nn.ReLU())\n        self.fc1 = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(4096, 4096),\n            nn.ReLU())\n        self.fc2= nn.Sequential(\n            nn.Linear(4096, num_classes))\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.layer5(out)\n        out = out.reshape(out.size(0), -1)\n        out = self.fc(out)\n        out = self.fc1(out)\n        out = self.fc2(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-08-05T17:40:09.400922Z","iopub.execute_input":"2024-08-05T17:40:09.401931Z","iopub.status.idle":"2024-08-05T17:40:09.414349Z","shell.execute_reply.started":"2024-08-05T17:40:09.401896Z","shell.execute_reply":"2024-08-05T17:40:09.413455Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# from AlexNet import *\nmodelB = AlexNetB(2).to(device)\nmodel = AlexNet(2).to(device)\nmodel = model\nlearning_rate = 1e-5\nepochs = 1\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n\nfor epoch in range(epochs):\n    for idx,(img,target) in enumerate(dataloader_train):\n        img = img.to(device=device)\n        target = target.to(device=device)\n\n        #forward pass\n        y_pred = model(img)\n\n        loss = criterion(y_pred,target)\n\n        # backward pass\n        loss.backward()\n\n        # weight update\n        optimizer.step()\n\n        optimizer.zero_grad()\n\n        ","metadata":{"execution":{"iopub.status.busy":"2024-08-05T17:40:12.464829Z","iopub.execute_input":"2024-08-05T17:40:12.465195Z","iopub.status.idle":"2024-08-05T17:41:14.036887Z","shell.execute_reply.started":"2024-08-05T17:40:12.465166Z","shell.execute_reply":"2024-08-05T17:41:14.036131Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"PATH = '/kaggle/working/AlexNet'\ntorch.save(model.state_dict(), PATH)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T17:41:18.529902Z","iopub.execute_input":"2024-08-05T17:41:18.530794Z","iopub.status.idle":"2024-08-05T17:41:19.171688Z","shell.execute_reply.started":"2024-08-05T17:41:18.530761Z","shell.execute_reply":"2024-08-05T17:41:19.170894Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# PATHB = '/kaggle/working/AlexNetB'\n# torch.save(modelB.state_dict(), PATHB)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T17:41:19.752932Z","iopub.execute_input":"2024-08-05T17:41:19.753305Z","iopub.status.idle":"2024-08-05T17:41:19.759928Z","shell.execute_reply.started":"2024-08-05T17:41:19.753276Z","shell.execute_reply":"2024-08-05T17:41:19.759030Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model = AlexNet(2)\nmodel.load_state_dict(torch.load(PATH))","metadata":{"execution":{"iopub.status.busy":"2024-08-05T17:41:21.341501Z","iopub.execute_input":"2024-08-05T17:41:21.342320Z","iopub.status.idle":"2024-08-05T17:41:22.136732Z","shell.execute_reply.started":"2024-08-05T17:41:21.342286Z","shell.execute_reply":"2024-08-05T17:41:22.135786Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"correct = 0\ntotal = 0\n# since we're not training, we don't need to calculate the gradients for our outputs\nwith torch.no_grad():\n    for data in dataloader_test:\n        images, labels = data\n#         labels = labels.to(device=device)\n#         images = images.to(device=device)\n        # calculate outputs by running images through the network\n        outputs = model(images)\n#         print(labels,outputs)\n        # the class with the highest energy is what we choose as prediction\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f'Accuracy of the network on the {len(dataloader_test)*128} test images: {100 * correct / total} %')","metadata":{"execution":{"iopub.status.busy":"2024-08-05T17:41:23.349384Z","iopub.execute_input":"2024-08-05T17:41:23.349754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare to count predictions for each class\nclasses = ('Negative','Positive')\ncorrect_pred = {classname: 0 for classname in classes}\ntotal_pred = {classname: 0 for classname in classes}\n\n# again no gradients needed\nwith torch.no_grad():\n    for data in dataloader_test:\n        images, labels = data\n        outputs = model(images)\n        _, predictions = torch.max(outputs, 1)\n        # collect the correct predictions for each class\n        for label, prediction in zip(labels, predictions):\n            if label == prediction:\n                correct_pred[classes[label]] += 1\n            total_pred[classes[label]] += 1\n\n\n# print accuracy for each class\nfor classname, correct_count in correct_pred.items():\n    accuracy = 100 * float(correct_count) / total_pred[classname]\n    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}